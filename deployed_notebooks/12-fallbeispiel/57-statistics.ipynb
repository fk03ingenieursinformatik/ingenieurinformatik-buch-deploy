{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d944af0b",
   "metadata": {},
   "source": [
    "# Bibliothek `statistics` (V)\n",
    "\n",
    "Dann kommt plötzlich Julias Kollegin vorbei und meint, dass sie bereits sehr gute Erfahrung mit der Python-Bibliothek `statistics` gemacht hat - auch eine native Bib. Die Bibliothek liefert nicht nur Mittelwerte und Standardabweichung sondern auch schon Quantile. Das ganze Sortieren, das Julia bereits angefangen hat, war also gar nicht notwendig.\n",
    "\n",
    "Julia ärgert sich ein wenig, dass sie nicht ordentlich rechechiert hat und entscheidet sich die Bibliothek zu nutzen - damit muss sie auch keine Tests implementieren, was ja auch noch ausstehen würde.\n",
    "\n",
    "## Einlesen der Daten\n",
    "\n",
    "Wie in den vorherigen Teilkapiteln liest Julia die CSV-Datei direkt aus dem Internet ein. Dafür reicht `urllib` aus der Standardbibliothek – es muss nichts installiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a37cb917",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "def _non_empty_lines(text):\n",
    "    return [ln.strip() for ln in text.strip().splitlines() if ln.strip()]\n",
    "\n",
    "\n",
    "def _ensure_comma_delimiter(lines):\n",
    "    \"\"\"\n",
    "    Zwischenlösung: Wir unterstützen NUR Komma.\n",
    "    Wenn es nach Semikolon aussieht, geben wir eine klare Fehlermeldung.\n",
    "    \"\"\"\n",
    "    if not lines:\n",
    "        raise ValueError(\"CSV ist leer.\")\n",
    "\n",
    "    first_line = lines[0]\n",
    "    if \",\" not in first_line and \";\" in first_line:\n",
    "        raise ValueError(\n",
    "            \"Unerwartetes Trennzeichen ';'. Dieser Parser erwartet Komma ',' als Trennzeichen.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def _parse_header(header_line):\n",
    "    header = [h.strip() for h in header_line.split(\",\")]\n",
    "    if not header or header[0] != \"datetime\":\n",
    "        raise ValueError(\n",
    "            \"Ungültiger Header: erste Spalte muss 'datetime' heißen (Komma ',' als Trennzeichen).\"\n",
    "        )\n",
    "    stations = header[1:]\n",
    "    if not stations:\n",
    "        raise ValueError(\"Header enthält keine Stationsspalten.\")\n",
    "    return header, stations\n",
    "\n",
    "\n",
    "def _parse_no2_value(value, station, line):\n",
    "    \"\"\"\n",
    "    Parsen eines einzelnen Messwerts.\n",
    "\n",
    "    - Leere Felder geben wir als None zurück (d.h. Messwert fehlt).\n",
    "    - Nicht-leere Felder müssen in float umwandelbar sein.\n",
    "    \"\"\"\n",
    "    value = value.strip()\n",
    "    if value == \"\":\n",
    "        return None\n",
    "    try:\n",
    "        return float(value)\n",
    "    except ValueError as e:\n",
    "        raise ValueError(\n",
    "            f\"Ungültiger Messwert {value!r} für {station!r} in Zeile: {line!r}.\"\n",
    "        ) from e\n",
    "\n",
    "\n",
    "def parse_air_quality_csv_v3(csv_text):\n",
    "    lines = _non_empty_lines(csv_text)\n",
    "    _ensure_comma_delimiter(lines)\n",
    "\n",
    "    header, stations = _parse_header(lines[0])\n",
    "    result = {s: {\"time\": [], \"no2\": []} for s in stations}\n",
    "\n",
    "    for line in lines[1:]:\n",
    "        if \",\" not in line and \";\" in line:\n",
    "            raise ValueError(\n",
    "                \"Unerwartetes Trennzeichen ';' in den Datenzeilen. Dieser Parser erwartet Komma ','.\"\n",
    "            )\n",
    "\n",
    "        parts = [p.strip() for p in line.split(\",\")]\n",
    "        if len(parts) > len(header):\n",
    "            raise ValueError(\n",
    "                f\"Zu viele Spalten in Zeile: {line!r} (erwartet {len(header)}, gefunden {len(parts)}).\"\n",
    "            )\n",
    "        if len(parts) < len(header):\n",
    "            parts = parts + [\"\"] * (len(header) - len(parts))\n",
    "\n",
    "        t = parts[0]\n",
    "        for idx, station in enumerate(stations, start=1):\n",
    "            parsed = _parse_no2_value(parts[idx], station, line)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "            result[station][\"time\"].append(t)\n",
    "            result[station][\"no2\"].append(parsed)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pandas-dev/pandas/main/doc/data/air_quality_no2.csv\"\n",
    "with urlopen(url) as response:\n",
    "    csv_text = response.read().decode(\"utf-8\")\n",
    "\n",
    "data = parse_air_quality_csv_v3(csv_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2f91a7",
   "metadata": {},
   "source": [
    "Damit die Ausgabe später hübscher aussieht, entfernt Julia noch das Präfix `station_` aus den Stationsnamen (wie schon im Histogramm-Kapitel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123fa318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Antwerp', 'London', 'Paris']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {k.replace(\"station_\", \"\").title(): v for k, v in data.items()}\n",
    "sorted(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cea7a6",
   "metadata": {},
   "source": [
    "Zur Erinnerung: Die Daten liegen als Dictionary vor, pro Station jeweils die Zeitstempel und die NO₂-Werte.\n",
    "\n",
    "Wenn Julia kurz prüfen möchte, ob alles passt, gibt sie eine kleine Vorschau aus (statt das komplette Dictionary in den Text zu kopieren)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae048014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Antwerp\": {\n",
      "    \"time\": [\n",
      "      \"2019-05-07 03:00:00\",\n",
      "      \"2019-05-07 04:00:00\",\n",
      "      \"2019-05-08 03:00:00\",\n",
      "      \"2019-05-08 04:00:00\",\n",
      "      \"2019-05-09 03:00:00\"\n",
      "    ],\n",
      "    \"no2\": [\n",
      "      50.5,\n",
      "      45.0,\n",
      "      23.0,\n",
      "      20.5,\n",
      "      20.0\n",
      "    ],\n",
      "    \"total\": 95\n",
      "  },\n",
      "  \"Paris\": {\n",
      "    \"time\": [\n",
      "      \"2019-05-07 03:00:00\",\n",
      "      \"2019-05-07 04:00:00\",\n",
      "      \"2019-05-07 05:00:00\",\n",
      "      \"2019-05-07 06:00:00\",\n",
      "      \"2019-05-07 07:00:00\"\n",
      "    ],\n",
      "    \"no2\": [\n",
      "      25.0,\n",
      "      27.7,\n",
      "      50.4,\n",
      "      61.9,\n",
      "      72.4\n",
      "    ],\n",
      "    \"total\": 1004\n",
      "  },\n",
      "  \"London\": {\n",
      "    \"time\": [\n",
      "      \"2019-05-07 02:00:00\",\n",
      "      \"2019-05-07 03:00:00\",\n",
      "      \"2019-05-07 04:00:00\",\n",
      "      \"2019-05-07 05:00:00\",\n",
      "      \"2019-05-07 07:00:00\"\n",
      "    ],\n",
      "    \"no2\": [\n",
      "      23.0,\n",
      "      19.0,\n",
      "      19.0,\n",
      "      16.0,\n",
      "      26.0\n",
      "    ],\n",
      "    \"total\": 969\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def preview_data(data, n=5):\n",
    "    return {\n",
    "        station: {\"time\": d[\"time\"][:n], \"no2\": d[\"no2\"][:n], \"total\": len(d[\"no2\"])}\n",
    "        for station, d in data.items()\n",
    "    }\n",
    "\n",
    "print(json.dumps(preview_data(data, n=5), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ea65a",
   "metadata": {},
   "source": [
    "## Finale Lösung\n",
    "\n",
    "Dann implementiert Julia die Statistiken mit der Bibliothek `statistics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057f6c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stat   Antwerp  Paris  London\n",
      "-----------------------------\n",
      "count  95       1004   969   \n",
      "mean   25.78    27.74  24.78 \n",
      "std    12.68    15.29  11.21 \n",
      "min    7.50     0.00   0.00  \n",
      "25%    16.75    16.50  19.00 \n",
      "50%    23.00    24.15  25.00 \n",
      "75%    34.50    35.92  31.00 \n",
      "max    74.50    97.00  97.00 \n"
     ]
    }
   ],
   "source": [
    "import statistics as st\n",
    "\n",
    "def describe(values):\n",
    "    \"\"\"\n",
    "    Ähnlich zu pandas.describe(), aber:\n",
    "    - ohne externe Bibliotheken\n",
    "    - Quartile über `statistics.quantiles(...)` (Nearest-Rank war oben nur ein didaktisches Beispiel)\n",
    "    \"\"\"\n",
    "    if not values:\n",
    "        raise ValueError(\"Leere Liste.\")\n",
    "\n",
    "    # quantiles(...) gibt für n=4 drei Werte zurück: [25%, 50%, 75%]\n",
    "    # Wir verwenden \"inclusive\", damit es auch für kleinere Listen definiert ist.\n",
    "    q25, q50, q75 = st.quantiles(values, n=4, method=\"inclusive\")\n",
    "    sv = sorted(values)  # nur für min/max (ohne Input zu verändern)\n",
    "\n",
    "    return {\n",
    "        \"count\": len(values),\n",
    "        \"mean\": st.mean(values),\n",
    "        \"std\": st.stdev(values) if len(values) >= 2 else 0.0,\n",
    "        \"min\": sv[0],\n",
    "        \"25%\": q25,\n",
    "        \"50%\": q50,\n",
    "        \"75%\": q75,\n",
    "        \"max\": sv[-1],\n",
    "    }\n",
    "\n",
    "\n",
    "def print_table(table_data, cols, precision=2):\n",
    "    header = [\"stat\"] + cols\n",
    "    rows = []\n",
    "\n",
    "    for stat, values in table_data.items():\n",
    "        row = [stat] + [\n",
    "            f\"{v:.{precision}f}\" if isinstance(v, float) else str(v)\n",
    "            for v in values\n",
    "        ]\n",
    "        rows.append(row)\n",
    "\n",
    "    col_widths = [\n",
    "        max(len(str(cell)) for cell in column)\n",
    "        for column in zip(header, *rows)\n",
    "    ]\n",
    "\n",
    "    def fmt_row(row):\n",
    "        return \"  \".join(cell.ljust(w) for cell, w in zip(row, col_widths))\n",
    "\n",
    "    print(fmt_row(header))\n",
    "    print(\"-\" * (sum(col_widths) + 2 * (len(col_widths) - 1)))\n",
    "    for row in rows:\n",
    "        print(fmt_row(row))\n",
    "\n",
    "\n",
    "results_dict = []\n",
    "cols = []\n",
    "\n",
    "for station in data:\n",
    "    result = describe(data[station][\"no2\"])\n",
    "    cols.append(station)\n",
    "    results_dict.append(result)\n",
    "\n",
    "table = {k: [row[k] for row in results_dict] for k in results_dict[0]}\n",
    "print_table(table, cols=cols)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "source_map": [
   10,
   23,
   112,
   116,
   119,
   125,
   135,
   141
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}